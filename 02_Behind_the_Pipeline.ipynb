{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9992303848266602},\n",
       " {'label': 'NEGATIVE', 'score': 0.9989625215530396}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", device=0)\n",
    "\n",
    "classifier([\n",
    "    \"I love playing basketball\",\n",
    "    \"I hate studying\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1045, 2293, 2652, 3455,  102],\n",
      "        [ 101, 1045, 5223, 5702,  102,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0]])}\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    \"I love playing basketball\",\n",
    "    \"I hate studying\",\n",
    "]\n",
    "\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutput(last_hidden_state=tensor([[[ 0.3825, -0.0303,  0.1281,  ...,  0.2931,  0.7915, -0.4785],\n",
      "         [ 0.7825,  0.2582, -0.1530,  ...,  0.2646,  0.7143, -0.3490],\n",
      "         [ 0.9320,  0.5608,  0.4751,  ...,  0.0192,  0.8268, -0.4745],\n",
      "         [ 0.5742,  0.1464,  0.0363,  ..., -0.0976,  0.3402, -0.5343],\n",
      "         [ 0.4953, -0.2668,  0.0419,  ..., -0.2285,  0.3109, -1.0238],\n",
      "         [ 1.0199,  0.1193,  0.0889,  ...,  0.6064,  0.2341, -0.8190]],\n",
      "\n",
      "        [[-0.0767,  0.8316, -0.1653,  ..., -0.1531, -0.5883, -0.0515],\n",
      "         [-0.1225,  0.9392, -0.0536,  ..., -0.3153, -0.4908,  0.2073],\n",
      "         [-0.1233,  1.0684,  0.0327,  ..., -0.2589, -0.4985,  0.0596],\n",
      "         [ 0.1809,  1.3178, -0.3163,  ..., -0.3060, -0.0386, -0.2794],\n",
      "         [ 0.4821,  0.7182, -0.2021,  ..., -0.0219, -0.2646, -0.1810],\n",
      "         [-0.2504,  0.8853, -0.3587,  ..., -0.3097, -0.3676,  0.0418]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)\n",
      "torch.Size([2, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel \n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModel.from_pretrained(checkpoint)\n",
    "\n",
    "outputs = model(**inputs) # **inputs passes the content of the dictionary as named arguments to the model forward method\n",
    "print(outputs)\n",
    "print(outputs.last_hidden_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[-3.5025,  3.6663],\n",
      "        [ 3.7671, -3.1028]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "\n",
    "outputs = model(**inputs)\n",
    "print(outputs)\n",
    "print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.5025,  3.6663],\n",
      "        [ 3.7671, -3.1028]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.6961e-04, 9.9923e-01],\n",
      "        [9.9896e-01, 1.0375e-03]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "pred = torch.nn.functional.softmax(outputs.logits, dim=-1) # dim=-1 means that the softmax is applied to the last dimension\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
